{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage example on notMNIST\n",
    "\n",
    "### First download the dataset from http://yaroslavvb.com/upload/notMNIST/notMNIST_small.mat\n",
    "\n",
    "- [ ] MLD issue \"post AKNN\" contains more margin experiments to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy as sp, time, scipy.io, sklearn\n",
    "import aknn_alg\n",
    "\n",
    "notMNIST_small = scipy.io.loadmat(\"notMNIST_small.mat\")['images'].reshape(784, 18724)\n",
    "nmn = (notMNIST_small.T - 255.0/2)/255.0\n",
    "labels = scipy.io.loadmat(\"notMNIST_small.mat\")['labels'].astype(int)\n",
    "labels_to_symbols = { 0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J' }\n",
    "labels = np.array([labels_to_symbols[x] for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor indices computed. Time:\t 8.779023885726929\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(aknn_alg)\n",
    "\n",
    "# Calculate list of exact Euclidean nearest neighbors for each point - use more neighbors for less abstaining at a given parameter setting.\n",
    "itime = time.time()\n",
    "nbrs_list = aknn_alg.calc_nbrs_exact(nmn, k=1000, use_nndescent=False)\n",
    "print('Neighbor indices computed. Time:\\t {}'.format(time.time() - itime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = nmn.shape[1]\n",
    "t = AnnoyIndex(dim, 'euclidean')  # Length of item vector that will be indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.77 s, sys: 453 ms, total: 2.23 s\n",
      "Wall time: 1.66 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#a = calc_nbrs_pynndescent(raw_data)\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(nmn.shape[0]):\n",
    "    t.add_item(i, nmn[i, :])\n",
    "\n",
    "t.build(10) # 10 trees\n",
    "t.save('test.ann')\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1059, 787, 364, 4336, 461, 962, 6438, 1009, 6655, 6822, 7423, 887, 5636, 591, 6960, 6203, 7047, 7142, 6641, 5996, 7336, 6061, 6159, 190, 7425, 4834, 5315, 6942, 7459, 1089, 588, 6220, 373, 7325, 7359, 6670, 485, 721, 834, 5645, 1690, 6393, 7092, 72, 5744, 6365, 6523, 5997, 6329, 7011, 6269, 6802, 7115, 6681, 1514, 5654, 7404, 6997, 6097, 33, 6536, 5893, 7148, 12293, 1602, 1560, 436, 5880, 55, 5824, 6078, 1534, 6025, 6444, 5896, 666, 6480, 6815, 6513, 6242, 5727, 6302, 6089, 6213, 5771, 6056, 6925, 6230, 1612, 7254, 6838, 6, 7306, 1274, 6714, 1176, 1391, 7180, 5704, 4543, 1536, 1249, 970, 6409, 1865, 6875, 7430, 6026, 6906, 1140, 814, 536, 1245, 6085, 7192, 6927, 6605, 4707, 7080, 7307, 6866, 5841, 6155, 7428, 6253, 5245, 920, 561, 7163, 7381, 6908, 6317, 1474, 6002, 14053, 7113, 1838, 5819, 6857, 5922, 10148, 17718, 6436, 7146, 5751, 7462, 81, 5691, 6869, 1196, 174, 413, 6826, 5696, 5887, 6123, 4826, 6237, 6516, 6889, 6340, 6630, 13529, 960, 6407, 136, 527, 6956, 4304, 7082, 603, 5660, 7015, 6627, 5780, 7264, 1713, 1712, 6841, 6578, 53, 1447, 5458, 1338, 8619, 6991, 6130, 5951, 6059, 936, 1743, 5758, 1807, 863, 6248, 5619, 6844, 16813, 1132, 7003, 6779, 7472, 5962, 5928, 12698, 6024, 7263, 6644, 1248, 7372, 720, 6534, 6479, 6117, 19, 6959, 6723, 6608, 1191, 1606, 1296, 1551, 7085, 1788, 7397, 7140, 14798, 6423, 6935, 432, 6819, 7301, 7378, 5895, 1637, 6044, 12739, 5672, 31, 377, 6789, 6545, 5987, 7411, 6241, 1739, 11572, 6625, 616, 6556, 7240, 7407, 338, 5711, 5630, 6720, 859, 777, 6628, 6953, 4813, 12194, 6659, 6471, 1740, 4118, 12243, 1193, 1674, 6614, 6642, 7145, 1527, 251, 6351, 1721, 6235, 7403, 180, 5823, 5879, 177, 7350, 6247, 1320, 6118, 343, 1004, 6897, 1652, 134, 880, 7317, 5960, 1253, 6882, 6336, 614, 5769, 163, 1493, 243, 14360, 7064, 867, 6898, 6818, 277, 5935, 897, 226, 6079, 6422, 6140, 6357, 7160, 7341, 6181, 6611, 522, 742, 6544, 1888, 7058, 6035, 5795, 453, 14498, 6784, 6276, 6492, 6139, 623, 6989, 6040, 7995, 6050, 7451, 6874, 5873, 2363, 7144, 5750, 1847, 7251, 352, 6349, 1545, 7480, 1552, 7153, 7253, 6319, 1464, 6404, 7414, 7221, 6715, 6279, 6215, 1100, 6475, 381, 7368, 582, 488, 5656, 7405, 1395, 11909, 7376, 7445, 7178, 538, 1497, 6274, 6286, 7216, 11532, 6506, 6031, 6481, 633, 7119, 1040, 6986, 6865, 262, 4604, 6420, 7385, 6941, 7075, 6275, 6728, 6557, 5617, 6400, 6946, 6288, 5714, 5907, 942, 1365, 6179, 6173, 7009, 7392, 7274, 1864, 91, 5807, 6260, 1268, 5838, 7125, 1694, 5748, 6310, 1559, 6048, 6013, 6426, 6259, 6298, 6315, 7474, 3707, 6555, 7356, 1758, 1678, 7007, 7471, 1106, 589, 6448, 1839, 14598, 7282, 127, 5869, 3442, 6700, 1008, 1457, 7380, 7257, 7056, 6111, 6799, 6006, 7224, 6967, 7233, 6372, 1849, 6070, 6082, 5815, 825, 1046, 6054, 14957, 5666, 6649, 653, 6562, 6199, 6697, 7279, 124, 1821, 7099, 5679, 5622, 6747, 664, 6308, 6386, 7173, 6724, 7174, 6138, 5694, 7065, 5768, 7084, 1152, 6443, 5699, 629, 5911, 6646, 13418, 7375, 6200, 6727, 7286, 7182, 1420, 7327, 7220, 1541, 6677, 6978, 5900, 6109, 6890, 6004, 337, 1662, 7043, 682, 6358, 937, 1215, 999, 5966, 1688, 9377, 13732, 547, 1596, 6300, 6896, 6833, 7195, 12600, 7481, 344, 7074, 415, 5990, 6033, 1790, 7424, 5749, 6624, 6679, 6974, 7406, 6721, 6411, 11724, 7416, 6860, 6984, 6341, 6171, 7149, 7203, 6528, 6913, 4356, 1635, 6698, 1240, 4754, 95, 1217, 7152, 6223, 7332, 7335, 7194, 7457, 6994, 6742, 7097, 1335, 13462, 184, 5839, 5814, 6362, 478, 7420, 1456, 6060, 1750, 6828, 7062, 6504, 5762, 6732, 6776, 5803, 1252, 6131, 7316, 1006, 7311, 2000, 5871, 18057, 1347, 140, 11314, 6188, 1312, 11557, 5791, 1525, 1867, 12605, 710, 14731, 6812, 102, 6271, 425, 6772, 254, 1461, 6470, 6932, 1130, 6626, 6314, 5836, 74, 7487, 154, 5820, 6756, 890, 1640, 1434, 331, 5721, 6291, 1000, 906, 71, 6391, 12323, 1371, 6565, 630, 565, 6900, 6703, 7168, 11726, 5792, 13325, 7309, 1684, 6141, 1333, 1638, 175, 6949, 1645, 7483, 6254, 6354, 6029, 7479, 5884, 6770, 11898, 643, 7357, 583, 1709, 8355, 559, 5730, 1092, 1571, 699, 7042, 7019, 1524, 7155, 753, 11263, 6496, 6394, 6664, 5860, 1212, 6290, 5738, 873, 6454, 7151, 5693, 6734, 1719, 112, 7928, 7298, 7127, 7057, 6021, 6769, 7066, 5868, 6170, 6105, 7256, 7337, 5798, 6258, 6665, 6115, 6952, 6787, 6634, 7278, 6183, 5710, 7841, 6752, 1704, 7034, 6335, 6127, 6312, 6418, 6868, 10031, 6012, 1506, 881, 8548, 4630, 1314, 5642, 1366, 7323, 14711, 6910, 6707, 1789, 6712, 1137, 286, 1044, 6682, 6635, 6184, 5757, 6197, 6246, 5834, 6316, 1840, 12723, 6658, 369, 1017, 5111, 378, 6224, 16038, 7266, 6615, 5944, 1470, 367, 6872, 406, 6809, 6853, 5525, 439, 6973, 6653, 6852, 6052, 6521, 6588, 1284, 6113, 150, 21, 5939, 272, 7394, 7177, 7408, 4049, 6692, 6196, 1384, 1186, 632, 4782, 1660, 5725, 6086, 5687, 1850, 6206, 5989, 9292, 7349, 7284, 1074, 7087, 1143, 7070, 5728, 1359, 6266, 5628, 5740, 6803, 13349, 6694, 1504, 5805, 6596, 7260, 1482, 5650, 6205, 1282, 5688, 6064, 7024, 7228, 7302, 14166, 273, 399, 14381, 7169, 7454, 7314, 6979, 255, 6477, 751, 6654, 16669, 6816, 6549, 13014, 1036, 6261, 6318, 6632, 5931, 6881, 6520, 6515, 6160, 209, 85, 6154, 7310, 6855, 690, 7438, 5978, 13291, 1573, 7456, 1112, 303, 1433, 6867, 12779, 333, 6669, 5875, 5972, 6473, 5735, 319, 12869, 1236, 17177, 5833, 6245, 1147, 119, 7287, 639, 5851, 6348, 6798, 7467, 15835, 5929, 1471, 6951, 5655, 5885, 1555, 5942, 1733, 705, 1445, 58, 6388, 1303, 1339, 5731, 1453, 6651, 6909, 758, 1598, 463, 913, 11803, 12531, 385, 6981, 11426, 216, 11252, 1563, 362, 1069, 7320, 513, 516, 14239, 5776, 4424, 1388, 6360, 70, 11959, 5344, 6508, 5971, 821, 786, 17223, 6593, 5709, 6204, 6168, 6432, 3153, 5937, 6356, 6571, 5718, 6231, 7098, 915, 5690, 14225, 996, 1024, 1810, 86, 7095, 5788, 5661, 1834, 733, 990, 6647, 13849, 16453, 6063, 1057, 6176, 6753, 5658, 5850, 1128, 6095, 6797, 803, 76, 1815, 6746, 6758, 6921, 6433, 1050, 563, 6766, 7465, 6121, 387, 746, 1022, 9093, 6891, 5891, 941, 567, 7447, 7143, 1332, 5842, 1819]\n"
     ]
    }
   ],
   "source": [
    "u = AnnoyIndex(dim, 'euclidean')\n",
    "u.load('test.ann') # super fast, will just mmap the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-78e69f565850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nns_by_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# will find the 1000 nearest neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type list)"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(nmn.shape[0]):\n",
    "    results.append(u.get_nns_by_item(i, 1000)) # will find the 1000 nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  555,  1210,  1444, ...,   828,   918,   847],\n",
       "       [ 1059,   787,   364, ...,  1332,  5842,  1819],\n",
       "       [ 1416,  1633,  1166, ..., 15974,  1180, 12151],\n",
       "       ...,\n",
       "       [ 9358,  3742, 14976, ..., 18207, 15929, 17690],\n",
       "       [18094, 17431, 18692, ..., 17809, 17289, 18671],\n",
       "       [17794, 18636, 17266, ..., 18612, 18143, 17405]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  555,  1444,  1210, ...,  6055,   709,  1381],\n",
       "       [ 1059,   787,   364, ...,  5060,  6867,  4856],\n",
       "       [ 1416,  1633,  1166, ...,  8957,  8599, 15470],\n",
       "       ...,\n",
       "       [ 9358,  3742, 14976, ...,  8708,  2002,   812],\n",
       "       [18094, 17431, 18692, ...,  8154, 18327, 16872],\n",
       "       [17794, 18636, 17266, ..., 18134, 17345, 16994]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbrs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make AKNN predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKNN predictions made. Time:\t 3.195094108581543\n"
     ]
    }
   ],
   "source": [
    "itime = time.time()\n",
    "aknn_predictions = aknn_alg.predict_nn_rule(nbrs_list, labels)\n",
    "print('AKNN predictions made. Time:\\t {}'.format(time.time() - itime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(aknn_alg)\n",
    "\n",
    "ref_data = nmn\n",
    "log_complexity = 1.0\n",
    "query_data = None\n",
    "max_k = 1000\n",
    "\n",
    "# itime = time.time()\n",
    "if query_data is None:\n",
    "    query_data = ref_data\n",
    "nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=max_k).fit(ref_data)\n",
    "distances, indices = nbrs.kneighbors(query_data)\n",
    "distinct_labels = np.unique(labels)\n",
    "rngarr = np.arange(indices.shape[1])+1\n",
    "query_nbrs = labels[indices]\n",
    "fracs_labels = [np.cumsum(query_nbrs == i, axis=1)/rngarr for i in distinct_labels]\n",
    "# print(\"Clustering computed. Time: {}\".format(time.time() - itime))\n",
    "thresholds = log_complexity/np.sqrt(np.arange(indices.shape[1]) + 1)\n",
    "numlabels_predicted = np.add.reduce([f > (thresholds + 1.0/len(distinct_labels)) for f in fracs_labels])\n",
    "adaptive_k = np.argmax(numlabels_predicted > 0, axis=1)\n",
    "\n",
    "# pred_labels = np.zeros(fracs_labels[0].shape[0]).astype(str)\n",
    "# for i in range(fracs_labels[0].shape[0]):\n",
    "#     if adaptive_k[i] == 0:\n",
    "#         pred_labels[i] = '?'\n",
    "#     else:\n",
    "#         lst = [f[i, adaptive_k[i]] for f in fracs_labels]\n",
    "#         pred_labels[i] = distinct_labels[np.argmax(lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKNN predictions made. Time:\t 13.257019996643066\n"
     ]
    }
   ],
   "source": [
    "itime = time.time()\n",
    "aknn_predictions_new = aknn_alg.aknn_predict(nmn, labels, max_k=1000)\n",
    "print('AKNN predictions made. Time:\\t {}'.format(time.time() - itime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-NN accuracy: \t\t0.8750267036957915\n",
      "AKNN accuracy (k <= 3): \t0.9701739850869926 \t\t Coverage: \t0.838015381328776\n",
      "\n",
      "5-NN accuracy: \t\t0.8833048493911557\n",
      "AKNN accuracy (k <= 5): \t0.9450811565536099 \t\t Coverage: \t0.9180196539201025\n",
      "\n",
      "7-NN accuracy: \t\t0.8836787011322367\n",
      "AKNN accuracy (k <= 7): \t0.9408167974157822 \t\t Coverage: \t0.9258705404828028\n",
      "\n",
      "8-NN accuracy: \t\t0.8834650715659047\n",
      "AKNN accuracy (k <= 8): \t0.9362406530053086 \t\t Coverage: \t0.935644093142491\n",
      "\n",
      "10-NN accuracy: \t\t0.8822901089510788\n",
      "AKNN accuracy (k <= 10): \t0.9322341209133662 \t\t Coverage: \t0.9425870540482802\n",
      "\n",
      "30-NN accuracy: \t\t0.8767891476180303\n",
      "AKNN accuracy (k <= 30): \t0.9158672400485169 \t\t Coverage: \t0.9687032685323649\n",
      "\n",
      "100-NN accuracy: \t\t0.858577227088229\n",
      "AKNN accuracy (k <= 100): \t0.9071918180829072 \t\t Coverage: \t0.9817346720786156\n",
      "\n",
      "Overall AKNN accuracy: 0.8925977355265969\n"
     ]
    }
   ],
   "source": [
    "kvals = [3,5,7,8,10,30,100]\n",
    "for i in range(len(kvals)):\n",
    "    knn_predictions = aknn_alg.knn_rule(nbrs_list, labels, k=kvals[i])\n",
    "    aknn_cov_ndces = aknn_predictions[1] <= kvals[i]\n",
    "    aknn_cov = np.mean(aknn_cov_ndces)\n",
    "    aknn_condacc = np.mean((aknn_predictions[0] == labels)[aknn_cov_ndces])\n",
    "    print('{}-NN accuracy: \\t\\t{}'.format(kvals[i], np.mean(knn_predictions == labels)))\n",
    "    print('AKNN accuracy (k <= {}): \\t{} \\t\\t Coverage: \\t{}\\n'.format(\n",
    "        kvals[i], aknn_condacc, aknn_cov))\n",
    "print('Overall AKNN accuracy: {}'.format(np.mean(aknn_predictions[0] == labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
